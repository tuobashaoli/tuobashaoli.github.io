---
categories: blog
date: '2024-02-23 22:29:18'
description: 一些深度学习的概念
layout: post
published: False
title: "关于深度学习"
tags: deeplearning
---

# 再说梯度下降

以低维举例，假设有个一维空间，也就是一个线，当然，可以是直线，也可以是曲线，假设这个一维空间如下图，

![avatar](/assets/images/func1.PNG)

有一个一维生物在这个一维空间里面，比方说在A点，那么从直观感受上来说，这个生物其实不知道他所在的地方是不是这个一维空间里面的最低点，必须有个至少二维的生物来告诉他，怎么走才能走到这个一维空间的最低点，那么这个二维以上的生物可以有俩种方式告诉这个生物怎么走到这个一维空间的最低点，

（1）一眼看出最低点所在的坐标，告诉一维生物往这个坐标走多少距离
（2）告诉一维生物所在的点的斜率，如果斜率是正的，那么这个一维生物就往左走，如果胜率是负的，那么就往右走，直到一维生物所在点的斜率是0，当然，这是个迭代的过程

以上的方法（1），就是用数学方法解决问题，当然，对于一元二次函数，初中数学知识就足以解决问题，对于及其复杂的一维空间，往往很难用数学方法解决，甚至数学方法没有解；对于方法（2），就是计算机算法解决问题，不论什么样的一维空间，都可以这么通用的解决

# 题外话

**二维生物告诉一维生物所在一维空间的斜率，以让一维生物到达该一维空间的最低点**，这就是**升维来解决当前维度的问题**，其中的斜率就是求导，上面说的求一维空间的最低点就是这种思想的典型案例，

那么同理，**三维生物告诉二维生物所在二维空间的'斜率'（到达二维后，这就是梯度向量了），以让二维生物到达该二维空间最低点**，这个的典型案例就是初中地理学到的地图等高线，生活在二维空间的二维生物难以从直观感受上来确定自己所在位置的高度，只能让三维生物来提供信息。这个方法的另一个应用，就是大学微积分中的，牛顿莱布尼兹公式，求导是降低维度，那么对应的升高维度，就是积分了，还记得该公式的描述吗，导数的在区域的积分（面积），就是原函数的区域上限对应的函数值减去区域下限对应的函数值。这也是**升维来解决当前维度的问题**的思想的应用

# 步长和局部最优解

对于学过高中数学的同学来说，上述的方法（2）有个明显的漏洞，那就是假如一维空间是如下所示，且该一维空间初始所处的位置不太好，如下A点，

![avatar](/assets/images/func2.PNG)

那么按照方法（2），走到的C点就不是最低点，而是局部最低点，这个就找错了。且称这个问题为局部最优解问题，先搁置一下。

另外，如果按照方法（2），那么每次这个一维生物该走多少呢？即**每次走的距离，称为步长**，如果步长很大，如下图所示，可能出现那么无论走多少次，都走不到最低点，

![avatar](/assets/images/func4.PNG)

那么就缩小步长，如果步长一直很小，那么就要走很多次，才能走到最低点，对应的就是算力的增加。

![avatar](/assets/images/func3.PNG)

# 如何进行梯度下降

以拟合一元一次函数的损失函数为例，如下

![avatar](/assets/images/dl1.PNG)

其中的m，就是用于计算梯度的训练数据的数量，当一次迭代中把全部的训练数据都投入来计算梯度，即m  = len(train_data)，自然得到的梯度向量就更加准确，但是这个时候所消耗的计算资源就十分高，这就是**批量梯度下降**

既然这个对计算资源要求高，那么为了降低计算资源，每次迭代计算梯度时，就不用全部的训练数据了，就随机选取一个样本，即 m = 1,
这样将计算资源的消耗降至最低，代价就是得到的梯度不准确，梯度的向量在每次迭代中差距可能较大，这样的结果可能会来回震荡，甚至不会收敛，这就是**随机梯度下降**，我愿称之为**猴子梯度下降（其实不是）**

那么这时，很容易从以上俩者做个折中，即每次随机选择小批量的训练数据，来计算梯度，即 1<m<<len(train_data),这就是**小批量梯度下降**,这样，提高了模型参数变化的收敛性，也不至于让迭代速度变慢，同时，由于训练数据选择是随机的，这也降低了陷入局部最优解的概率。

总结：

![avatar](/assets/images/dl_gradient.PNG)

学习视频：[什么是小批量梯度下降，和批量梯度下降、随机梯度下降有什么不同](https://www.bilibili.com/video/BV13p4y1g7eQ/?share_source=copy_web&vd_source=1e1a8470626ff3354bcd0d9c492ad7d2)

# 